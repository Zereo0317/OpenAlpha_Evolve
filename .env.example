FLASH_API_KEY=API_KEY_FLASH
FLASH_MODEL=gemini/gemini-2.5-flash-preview-05-20

PRO_API_KEY=API_KEY_PRO
PRO_MODEL=gemini/gemini-2.5-pro

EVALUATION_API_KEY=API_KEY_EVAL
EVALUATION_MODEL=gpt-4o

# These are optional
# FLASH_BASE_URL=http://localhost:11434
# PRO_BASE_URL=your_pro_base_url_if_needed
# EVALUATION_BASE_URL=http://localhost:11434

# --- LiteLLM Configuration ---
# Default model string for litellm (e.g., "gpt-3.5-turbo", "ollama/mistral", "claude-3-haiku-20240307")
# See litellm documentation for more model strings: https://docs.litellm.ai/docs/providers
LITELLM_DEFAULT_MODEL="gemini/gemini-2.5-flash-preview-05-20"
GEMINI_API_KEY=""

# API keys for models accessed via litellm should generally be set as environment variables
# that litellm recognizes (e.g., OPENAI_API_KEY, COHERE_API_KEY, ANTHROPIC_API_KEY, GOOGLE_API_KEY).
# litellm will automatically pick these up. Refer to litellm documentation for specific provider needs.
# Example:
# OPENAI_API_KEY=your_openai_api_key
# AZURE_API_KEY=your_azure_api_key # (for Azure OpenAI, also need other AZURE_* vars)

# LITELLM_MAX_TOKENS=4096
# LITELLM_TEMPERATURE=1.0
# LITELLM_TOP_P=0.9
# LITELLM_TOP_K=40
